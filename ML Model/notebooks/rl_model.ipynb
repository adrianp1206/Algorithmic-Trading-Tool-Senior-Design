{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the `src` directory\n",
    "src_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "# Add the `src` directory to the Python path\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from rl_model import StockPredictionEnv\n",
    "\n",
    "# Initialize the environment with your models and data\n",
    "# Replace `lstm_model`, `xgboost_model`, `nlp_model`, `historical_data`, and `technical_indicators` with actual instances\n",
    "env = StockPredictionEnv(\n",
    "    lstm_model=lstm_model,\n",
    "    xgboost_model=xgboost_model,\n",
    "    nlp_model=nlp_model,\n",
    "    historical_data=historical_data,\n",
    "    technical_indicators=technical_indicators\n",
    ")\n",
    "\n",
    "# Initialize PPO Agent with the environment\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the PPO agent on the environment\n",
    "# Adjust `total_timesteps` based on your computational resources and desired training duration\n",
    "model.learn(total_timesteps=10000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
